{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1 ğŸ”¹ Training Loss: 3.8719 ğŸ”¹ Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 2 ğŸ”¹ Training Loss: 1.6973 ğŸ”¹ Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3 ğŸ”¹ Training Loss: 1.2012 ğŸ”¹ Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 4 ğŸ”¹ Training Loss: 0.9646 ğŸ”¹ Learning Rate: 0.000099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 5 ğŸ”¹ Training Loss: 0.8250 ğŸ”¹ Learning Rate: 0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 6 ğŸ”¹ Training Loss: 0.7277 ğŸ”¹ Learning Rate: 0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 7 ğŸ”¹ Training Loss: 0.6563 ğŸ”¹ Learning Rate: 0.000096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 8 ğŸ”¹ Training Loss: 0.5954 ğŸ”¹ Learning Rate: 0.000095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 9 ğŸ”¹ Training Loss: 0.5557 ğŸ”¹ Learning Rate: 0.000094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 10 ğŸ”¹ Training Loss: 0.5324 ğŸ”¹ Learning Rate: 0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 11 ğŸ”¹ Training Loss: 0.4970 ğŸ”¹ Learning Rate: 0.000090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 12 ğŸ”¹ Training Loss: 0.4687 ğŸ”¹ Learning Rate: 0.000089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 13 ğŸ”¹ Training Loss: 0.4425 ğŸ”¹ Learning Rate: 0.000086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 14 ğŸ”¹ Training Loss: 0.4283 ğŸ”¹ Learning Rate: 0.000084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 15 ğŸ”¹ Training Loss: 0.4132 ğŸ”¹ Learning Rate: 0.000082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 16 ğŸ”¹ Training Loss: 0.3805 ğŸ”¹ Learning Rate: 0.000079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 17 ğŸ”¹ Training Loss: 0.3704 ğŸ”¹ Learning Rate: 0.000077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 18 ğŸ”¹ Training Loss: 0.3636 ğŸ”¹ Learning Rate: 0.000074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 19 ğŸ”¹ Training Loss: 0.3428 ğŸ”¹ Learning Rate: 0.000071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 20 ğŸ”¹ Training Loss: 0.3227 ğŸ”¹ Learning Rate: 0.000068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 21 ğŸ”¹ Training Loss: 0.3160 ğŸ”¹ Learning Rate: 0.000065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 22 ğŸ”¹ Training Loss: 0.2962 ğŸ”¹ Learning Rate: 0.000062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 23 ğŸ”¹ Training Loss: 0.2868 ğŸ”¹ Learning Rate: 0.000059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 24 ğŸ”¹ Training Loss: 0.2685 ğŸ”¹ Learning Rate: 0.000056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 25 ğŸ”¹ Training Loss: 0.2656 ğŸ”¹ Learning Rate: 0.000053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 26 ğŸ”¹ Training Loss: 0.2566 ğŸ”¹ Learning Rate: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 27 ğŸ”¹ Training Loss: 0.2417 ğŸ”¹ Learning Rate: 0.000047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 28 ğŸ”¹ Training Loss: 0.2328 ğŸ”¹ Learning Rate: 0.000044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 29 ğŸ”¹ Training Loss: 0.2240 ğŸ”¹ Learning Rate: 0.000041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 30 ğŸ”¹ Training Loss: 0.2166 ğŸ”¹ Learning Rate: 0.000038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 31 ğŸ”¹ Training Loss: 0.2089 ğŸ”¹ Learning Rate: 0.000035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 32 ğŸ”¹ Training Loss: 0.2045 ğŸ”¹ Learning Rate: 0.000032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 33 ğŸ”¹ Training Loss: 0.1976 ğŸ”¹ Learning Rate: 0.000029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 34 ğŸ”¹ Training Loss: 0.1835 ğŸ”¹ Learning Rate: 0.000026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 35 ğŸ”¹ Training Loss: 0.1810 ğŸ”¹ Learning Rate: 0.000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 36 ğŸ”¹ Training Loss: 0.1731 ğŸ”¹ Learning Rate: 0.000021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 37 ğŸ”¹ Training Loss: 0.1679 ğŸ”¹ Learning Rate: 0.000018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 38 ğŸ”¹ Training Loss: 0.1617 ğŸ”¹ Learning Rate: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 39 ğŸ”¹ Training Loss: 0.1531 ğŸ”¹ Learning Rate: 0.000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 40 ğŸ”¹ Training Loss: 0.1620 ğŸ”¹ Learning Rate: 0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 41 ğŸ”¹ Training Loss: 0.1544 ğŸ”¹ Learning Rate: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 42 ğŸ”¹ Training Loss: 0.1461 ğŸ”¹ Learning Rate: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 43 ğŸ”¹ Training Loss: 0.1440 ğŸ”¹ Learning Rate: 0.000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 44 ğŸ”¹ Training Loss: 0.1453 ğŸ”¹ Learning Rate: 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 45 ğŸ”¹ Training Loss: 0.1373 ğŸ”¹ Learning Rate: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 46 ğŸ”¹ Training Loss: 0.1356 ğŸ”¹ Learning Rate: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 47 ğŸ”¹ Training Loss: 0.1355 ğŸ”¹ Learning Rate: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 48 ğŸ”¹ Training Loss: 0.1351 ğŸ”¹ Learning Rate: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 49 ğŸ”¹ Training Loss: 0.1416 ğŸ”¹ Learning Rate: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 50 ğŸ”¹ Training Loss: 0.1350 ğŸ”¹ Learning Rate: 0.000000\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ../checkpoints\\swin_tiny_patch4_window7_224_20250528_023613.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8258/8258 [04:00<00:00, 34.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: ../submissions\\submission_swin_tiny_patch4_window7_224_20250528_023613.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm import create_model\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed=28):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(28)\n",
    "\n",
    "# âœ… ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_root = f'../data/train2'\n",
    "test_csv_path = '../data/test.csv'\n",
    "sample_sub_path = '../data/sample_submission.csv'\n",
    "save_dir = '../submissions'\n",
    "base_save_dir = '../checkpoints'\n",
    "num_epochs = 45\n",
    "batch_size = 32\n",
    "\n",
    "best_model_name = 'swin_tiny_patch4_window7_224'\n",
    "\n",
    "# âœ… ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "from dataloaders.loaders import get_dataloaders\n",
    "from models.train_utils import train_one_epoch\n",
    "\n",
    "dataloaders = get_dataloaders(data_root, batch_size=batch_size, val_ratio=0.0, return_path=False)\n",
    "train_loader = dataloaders[best_model_name]['train']\n",
    "class_names = dataloaders[best_model_name]['classes']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = create_model(best_model_name, pretrained=True, num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "print(\"ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"ğŸ“˜ Epoch {epoch + 1} ğŸ”¹ Training Loss: {train_loss:.4f} ğŸ”¹ Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# âœ… ëª¨ë¸ ì €ì¥\n",
    "os.makedirs(base_save_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_path = os.path.join(base_save_dir, f'{best_model_name}_{timestamp}.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "submission_template = pd.read_csv(sample_sub_path)\n",
    "submission_class_names = submission_template.columns.tolist()[1:]\n",
    "\n",
    "# âœ… ì˜ˆì¸¡\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc='ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡'):\n",
    "        img_path = os.path.join('../data', row['img_path'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "        results.append(prob)\n",
    "\n",
    "# âœ… ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission_df = pd.DataFrame(results, columns=class_names)\n",
    "submission_df.insert(0, 'ID', test_df['ID'])\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "submission_path = os.path.join(save_dir, f'submission_{best_model_name}_{timestamp}.csv')\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1\n",
      "   ğŸ”¹ Training Loss: 5.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 2\n",
      "   ğŸ”¹ Training Loss: 3.8131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3\n",
      "   ğŸ”¹ Training Loss: 1.8237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 4\n",
      "   ğŸ”¹ Training Loss: 1.1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 5\n",
      "   ğŸ”¹ Training Loss: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8258/8258 [03:13<00:00, 42.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: ../submissions\\submission_vit_base_patch16_224_20250524_125031.csv\n",
      "ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1\n",
      "   ğŸ”¹ Training Loss: 5.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 2\n",
      "   ğŸ”¹ Training Loss: 4.7529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3\n",
      "   ğŸ”¹ Training Loss: 2.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 4\n",
      "   ğŸ”¹ Training Loss: 1.4714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 5\n",
      "   ğŸ”¹ Training Loss: 1.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8258/8258 [03:07<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: ../submissions\\submission_vit_base_patch16_224_20250524_135840.csv\n",
      "ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1\n",
      "   ğŸ”¹ Training Loss: 5.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 2\n",
      "   ğŸ”¹ Training Loss: 5.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3\n",
      "   ğŸ”¹ Training Loss: 3.1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 4\n",
      "   ğŸ”¹ Training Loss: 1.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 5\n",
      "   ğŸ”¹ Training Loss: 1.2885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8258/8258 [02:17<00:00, 60.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: ../submissions\\submission_vit_base_patch16_224_20250524_150508.csv\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from timm import create_model\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "# from datetime import datetime\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# def seed_everything(seed=28):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# seed_everything(28)\n",
    "\n",
    "# # âœ… ì„¤ì •\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# data_root = f'../data/train2'\n",
    "# test_csv_path = '../data/test.csv'\n",
    "# sample_sub_path = '../data/sample_submission.csv'\n",
    "# save_dir = '../submissions'\n",
    "# base_save_dir = '../checkpoints'  # ğŸ”¸ ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì¶”ê°€\n",
    "# num_epochs = 50\n",
    "# patience = 3\n",
    "# batch_size = 32\n",
    "\n",
    "# best_model_name = 'vit_base_patch16_224'\n",
    "\n",
    "# # âœ… ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "# from dataloaders.loaders import get_dataloaders\n",
    "# from models.train_utils import train_one_epoch, EarlyStopping\n",
    "\n",
    "# dataloaders = get_dataloaders(data_root, batch_size=batch_size, val_ratio=0.0, return_path=False)\n",
    "# train_loader = dataloaders[best_model_name]['train']\n",
    "# class_names = dataloaders[best_model_name]['classes']\n",
    "# num_classes = len(class_names)\n",
    "\n",
    "# model = create_model(best_model_name, pretrained=True, num_classes=num_classes).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "# early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "# print(\"ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#     print(f\"ğŸ“˜ Epoch {epoch + 1} ğŸ”¹ Training Loss: {train_loss:.4f} ğŸ”¹ Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "#     scheduler.step()\n",
    "#     early_stopping(train_loss, model)\n",
    "#     if early_stopping.early_stop:\n",
    "#         print(\"â›” Early stopping ë°œìƒ\")\n",
    "#         break\n",
    "\n",
    "# # âœ… ëª¨ë¸ ì €ì¥\n",
    "# model.load_state_dict(early_stopping.best_model_state)\n",
    "# os.makedirs(base_save_dir, exist_ok=True)\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# model_path = os.path.join(base_save_dir, f'{best_model_name}_{timestamp}.pth')\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "# print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}\")\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# # âœ… í…ŒìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.485, 0.456, 0.406],\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# # âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "# test_df = pd.read_csv(test_csv_path)\n",
    "# submission_template = pd.read_csv(sample_sub_path)\n",
    "# submission_class_names = submission_template.columns.tolist()[1:]\n",
    "\n",
    "# # âœ… ì˜ˆì¸¡\n",
    "# results = []\n",
    "# with torch.no_grad():\n",
    "#     for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc='ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡'):\n",
    "#         img_path = os.path.join('../data', row['img_path'])\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "#         input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "#         output = model(input_tensor)\n",
    "#         prob = torch.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "#         results.append(prob)\n",
    "\n",
    "# # âœ… ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "# submission_df = pd.DataFrame(results, columns=class_names)\n",
    "# submission_df.insert(0, 'ID', test_df['ID'])\n",
    "\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# submission_path = os.path.join(save_dir, f'submission_{best_model_name}_{timestamp}.csv')\n",
    "# submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "# print(f\"âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}\\n\")\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath('..'))  # ìƒìœ„ í´ë” ì¶”ê°€\n",
    "\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from timm import create_model\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "# from datetime import datetime\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# def seed_everything(seed=28):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "\n",
    "#     # cuDNN ì—°ì‚° ê²°ì •ì  ì„¤ì •\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# seed_everything(28)\n",
    "\n",
    "# # âœ… ì„¤ì •\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# data_root = f'../data/train2'\n",
    "# test_csv_path = '../data/test.csv'\n",
    "# sample_sub_path = '../data/sample_submission.csv'\n",
    "# save_dir = '../submissions'\n",
    "# num_epochs = 10\n",
    "# patience = 3\n",
    "# batch_size = 32\n",
    "\n",
    "# # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.\n",
    "# best_model_name = 'vit_base_patch16_224'\n",
    "\n",
    "# # âœ… ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "# from dataloaders.loaders import get_dataloaders\n",
    "# from models.train_utils import train_one_epoch, EarlyStopping\n",
    "\n",
    "# dataloaders = get_dataloaders(data_root, batch_size=batch_size, val_ratio=0.0, return_path=False)\n",
    "# train_loader = dataloaders[best_model_name]['train']\n",
    "# class_names = dataloaders[best_model_name]['classes']\n",
    "# num_classes = len(class_names)\n",
    "\n",
    "# model = create_model(best_model_name, pretrained=True, num_classes=num_classes).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "# early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "# print(\"ğŸ” ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì‹œì‘\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#     print(f\"ğŸ“˜ Epoch {epoch + 1}\")\n",
    "#     print(f\"   ğŸ”¹ Training Loss: {train_loss:.4f}\")\n",
    "#     scheduler.step()\n",
    "#     early_stopping(train_loss, model)\n",
    "#     if early_stopping.early_stop:\n",
    "#         print(\"â›” Early stopping ë°œìƒ\")\n",
    "#         break\n",
    "\n",
    "# model.load_state_dict(early_stopping.best_model_state)\n",
    "# model.eval()\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.485, 0.456, 0.406],\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# # âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "# test_df = pd.read_csv(test_csv_path)\n",
    "# submission_template = pd.read_csv(sample_sub_path)\n",
    "# submission_class_names = submission_template.columns.tolist()[1:]\n",
    "\n",
    "# # âœ… ì˜ˆì¸¡\n",
    "# results = []\n",
    "# with torch.no_grad():\n",
    "#     for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc='ğŸ” í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡'):\n",
    "#         img_path = os.path.join('../data', row['img_path'])\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "#         input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "#         output = model(input_tensor)\n",
    "#         prob = torch.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "#         results.append(prob)\n",
    "\n",
    "# # âœ… ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "# submission_df = pd.DataFrame(results, columns=class_names)\n",
    "# submission_df.insert(0, 'ID', test_df['ID'])\n",
    "\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# submission_path = os.path.join(save_dir, f'submission_{best_model_name}_{timestamp}.csv')\n",
    "# submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "# print(f\"âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
