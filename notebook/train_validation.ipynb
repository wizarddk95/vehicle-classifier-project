{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³„ì¸µì  ë¶„í•  í™•ì¸\n",
      "í•™ìŠµ ë°ì´í„° ê°œìˆ˜: 25112\n",
      "ê²€ì¦ ë°ì´í„° ê°œìˆ˜: 6279\n",
      "ì´ ë°ì´í„° ê°œìˆ˜: 31391\n",
      "\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘: swin_tiny_patch4_window7_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1 train_loss: 5.1206 | learning_rate: 0.0001 | âœ… Acc: 0.4904 | LogLoss: 2.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 2 train_loss: 3.5131 | learning_rate: 0.0001 | âœ… Acc: 0.7600 | LogLoss: 1.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3 train_loss: 3.0332 | learning_rate: 0.0001 | âœ… Acc: 0.8264 | LogLoss: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 4 train_loss: 2.7793 | learning_rate: 0.0001 | âœ… Acc: 0.8584 | LogLoss: 0.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 5 train_loss: 2.6637 | learning_rate: 0.0001 | âœ… Acc: 0.8772 | LogLoss: 0.5457\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 6 train_loss: 2.4999 | learning_rate: 0.0001 | âœ… Acc: 0.8946 | LogLoss: 0.4224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 7 train_loss: 2.4755 | learning_rate: 0.0001 | âœ… Acc: 0.9016 | LogLoss: 0.4630\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 8 train_loss: 2.3271 | learning_rate: 0.0001 | âœ… Acc: 0.9169 | LogLoss: 0.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 9 train_loss: 2.2919 | learning_rate: 0.0001 | âœ… Acc: 0.9181 | LogLoss: 0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 10 train_loss: 2.2288 | learning_rate: 0.0001 | âœ… Acc: 0.9271 | LogLoss: 0.3275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 11 train_loss: 2.2036 | learning_rate: 0.0001 | âœ… Acc: 0.9212 | LogLoss: 0.3480\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 12 train_loss: 2.1269 | learning_rate: 0.0001 | âœ… Acc: 0.9334 | LogLoss: 0.3003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 13 train_loss: 2.0794 | learning_rate: 0.0001 | âœ… Acc: 0.9309 | LogLoss: 0.3232\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 14 train_loss: 2.0590 | learning_rate: 0.0001 | âœ… Acc: 0.9369 | LogLoss: 0.2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 15 train_loss: 2.0642 | learning_rate: 0.0001 | âœ… Acc: 0.9392 | LogLoss: 0.2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 16 train_loss: 1.9866 | learning_rate: 0.0001 | âœ… Acc: 0.9411 | LogLoss: 0.2990\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 17 train_loss: 1.9819 | learning_rate: 0.0001 | âœ… Acc: 0.9423 | LogLoss: 0.2840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 18 train_loss: 1.9174 | learning_rate: 0.0001 | âœ… Acc: 0.9385 | LogLoss: 0.2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 19 train_loss: 1.9159 | learning_rate: 0.0001 | âœ… Acc: 0.9427 | LogLoss: 0.2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 20 train_loss: 1.9155 | learning_rate: 0.0001 | âœ… Acc: 0.9433 | LogLoss: 0.2874\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 21 train_loss: 1.9317 | learning_rate: 0.0001 | âœ… Acc: 0.9481 | LogLoss: 0.2454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 22 train_loss: 1.9134 | learning_rate: 0.0001 | âœ… Acc: 0.9481 | LogLoss: 0.2624\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 23 train_loss: 1.8287 | learning_rate: 0.0001 | âœ… Acc: 0.9455 | LogLoss: 0.2561\n",
      "ğŸ“‰ EarlyStopping: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 24 train_loss: 1.8293 | learning_rate: 0.0000 | âœ… Acc: 0.9484 | LogLoss: 0.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 25 train_loss: 1.7948 | learning_rate: 0.0000 | âœ… Acc: 0.9509 | LogLoss: 0.2425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 26 train_loss: 1.7924 | learning_rate: 0.0000 | âœ… Acc: 0.9541 | LogLoss: 0.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 27 train_loss: 1.7791 | learning_rate: 0.0000 | âœ… Acc: 0.9533 | LogLoss: 0.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 28 train_loss: 1.7113 | learning_rate: 0.0000 | âœ… Acc: 0.9546 | LogLoss: 0.2512\n",
      "ğŸ“‰ EarlyStopping: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 29 train_loss: 1.7362 | learning_rate: 0.0000 | âœ… Acc: 0.9572 | LogLoss: 0.2360\n",
      "ğŸ“‰ EarlyStopping: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 30 train_loss: 1.7105 | learning_rate: 0.0000 | âœ… Acc: 0.9573 | LogLoss: 0.2412\n",
      "ğŸ“‰ EarlyStopping: 3/3\n",
      "â›” Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swin_tiny_patch4_window7_224</td>\n",
       "      <td>0.957318</td>\n",
       "      <td>0.241222</td>\n",
       "      <td>20250528_193828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  accuracy  log_loss        timestamp\n",
       "0  swin_tiny_patch4_window7_224  0.957318  0.241222  20250528_193828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timm import create_model\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from dataloaders.loaders import get_dataloaders\n",
    "from models.train_utils import train_one_epoch, evaluate, EarlyStopping, multiclass_log_loss\n",
    "from analysis.result_plotter import analyze_model_output\n",
    "\n",
    "from timm.data import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[3]\n",
    "    H = size[2]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def apply_cutmix(x, y, num_classes, beta=1.0):\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    rand_index = torch.randperm(x.size(0)).to(x.device)\n",
    "    y1 = F.one_hot(y, num_classes=num_classes).float()\n",
    "    y2 = y1[rand_index]\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bby1:bby2, bbx1:bbx2] = x[rand_index, :, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n",
    "    y_mix = y1 * lam + y2 * (1. - lam)\n",
    "    return x, y_mix\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def seed_everything(seed=28):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(28)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# âœ… ì„¤ì •\n",
    "data_root = '../data/train2'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 45\n",
    "patience = 3\n",
    "batch_size = 32\n",
    "base_log_dir = \"../runs\"\n",
    "os.makedirs(base_log_dir, exist_ok=True)\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë” êµ¬ì„±\n",
    "dataloaders = get_dataloaders(data_root, batch_size=batch_size)\n",
    "\n",
    "# ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ë°ì´í„° ìˆ˜ í™•ì¸\n",
    "first_model_name = list(dataloaders.keys())[0]\n",
    "train_loader = dataloaders[first_model_name]['train']\n",
    "val_loader = dataloaders[first_model_name]['val']\n",
    "print(f\"í•™ìŠµ ë°ì´í„° ê°œìˆ˜: {len(train_loader.dataset)}\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„° ê°œìˆ˜: {len(val_loader.dataset)}\")\n",
    "print(f\"ì´ ë°ì´í„° ê°œìˆ˜: {len(train_loader.dataset) + len(val_loader.dataset)}\")\n",
    "\n",
    "results = []\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "for model_name, loaders in dataloaders.items():\n",
    "    print(f\"\\nğŸš€ í•™ìŠµ ì‹œì‘: {model_name}\")\n",
    "    \n",
    "    log_dir = os.path.join(base_log_dir, f\"{model_name}_{timestamp}\")\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    model = create_model(model_name, pretrained=True, num_classes=len(loaders['classes'])).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    # scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    # mixup_fn = Mixup(\n",
    "    #     mixup_alpha=0.8,\n",
    "    #     cutmix_alpha=1.0,\n",
    "    #     cutmix_minmax=None,\n",
    "    #     prob=0.5,\n",
    "    #     switch_prob=0.5,\n",
    "    #     mode='batch',\n",
    "    #     label_smoothing=0.1,\n",
    "    #     num_classes=396  # í´ë˜ìŠ¤ ìˆ˜\n",
    "    # )\n",
    "\n",
    "        # num_classes ì •ì˜\n",
    "    num_classes = len(loaders['classes'])\n",
    "\n",
    "    # cutmix_fn ì •ì˜\n",
    "    cutmix_fn = lambda x, y: apply_cutmix(x, y, num_classes=num_classes, beta=1.0)\n",
    "\n",
    "    # criterion ë³€ê²½\n",
    "    criterion = SoftTargetCrossEntropy()  # Mixup & CutMix ì‚¬ìš© ì‹œ\n",
    "    # criterion = nn.CrossEntropyLoss()   # ì‚¬ìš© ì•ˆ í•  ê²½ìš°\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f\"\\nğŸ“˜ Epoch {epoch + 1}\")\n",
    "        train_loss = train_one_epoch(model, loaders['train'], criterion, optimizer, device, cutmix_fn)\n",
    "        # train_loss = train_one_epoch(model, loaders['train'], criterion, optimizer, device)\n",
    "        y_pred, y_prob, y_true, y_id, _ = evaluate(model, loaders['val'], device)\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        class_list = [str(i) for i in range(y_prob.shape[1])]\n",
    "        prob_df = pd.DataFrame(y_prob, columns=class_list)\n",
    "        prob_df.insert(0, 'ID', y_id)\n",
    "        label_df = pd.DataFrame({'ID': y_id, 'label': [str(l) for l in y_true]})\n",
    "\n",
    "        logloss = multiclass_log_loss(label_df, prob_df)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", logloss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/Validation\", acc, epoch)\n",
    "        writer.add_scalar(\"LearningRate\", scheduler.get_last_lr()[0], epoch)\n",
    "\n",
    "        print(f\"ğŸ“˜ Epoch {epoch + 1} train_loss: {train_loss:.4f} | learning_rate: {scheduler.get_last_lr()[0]:.6f} | âœ… Acc: {acc:.4f} | LogLoss: {logloss:.4f}\")\n",
    "        scheduler.step()\n",
    "        early_stopping(logloss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"â›” Early stopping triggered.\")\n",
    "            break \n",
    "\n",
    "    model.load_state_dict(early_stopping.best_model_state)\n",
    "    writer.close()\n",
    "\n",
    "    # âœ… ë¶„ì„ ê²°ê³¼ ìë™ ì €ì¥\n",
    "    val_indices = loaders['val'].dataset.indices if hasattr(loaders['val'].dataset, 'indices') else list(range(len(loaders['val'].dataset)))\n",
    "    base_dataset = loaders['val'].dataset.dataset\n",
    "    image_paths = [base_dataset.samples[i][0] for i in val_indices]\n",
    "\n",
    "    analyze_model_output(\n",
    "        model_name=model_name,\n",
    "        timestamp=timestamp,\n",
    "        image_paths=image_paths,\n",
    "        y_pred=y_pred,\n",
    "        y_prob=y_prob,\n",
    "        y_true=y_true,\n",
    "        class_names=loaders['classes']\n",
    "    )\n",
    "\n",
    "    results.append({'model': model_name, 'accuracy': acc, 'log_loss': logloss, 'timestamp': timestamp})\n",
    "\n",
    "# âœ… ìµœì¢… ë¹„êµ ê²°ê³¼\n",
    "df_result = pd.DataFrame(results).sort_values(by='log_loss')\n",
    "display(df_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
