{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def crop_roof_area(image, height_ratio=0.3):\n",
    "    width, height = image.size\n",
    "    crop_height = int(height * height_ratio)\n",
    "    return image.crop((0, 0, width, crop_height))\n",
    "\n",
    "def generate_classwise_roof_crops(data_root, save_root, ratio=0.2, height_ratio=0.4):\n",
    "    dataset = datasets.ImageFolder(data_root)\n",
    "    class_to_idx = dataset.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "    classwise_paths = {cls: [] for cls in dataset.classes}\n",
    "    for path, label in dataset.samples:\n",
    "        classwise_paths[idx_to_class[label]].append(path)\n",
    "\n",
    "    for cls_name, paths in classwise_paths.items():\n",
    "        cls_out_dir = os.path.join(save_root, cls_name)\n",
    "        os.makedirs(cls_out_dir, exist_ok=True)\n",
    "\n",
    "        num_to_generate = int(len(paths) * ratio)\n",
    "        selected_paths = random.sample(paths, num_to_generate)\n",
    "\n",
    "        for i, img_path in enumerate(selected_paths):\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            roof = crop_roof_area(img, height_ratio=height_ratio)\n",
    "            new_name = f\"roof_{i}_{os.path.basename(img_path)}\"\n",
    "            roof.save(os.path.join(cls_out_dir, new_name))\n",
    "\n",
    "        # âœ… ì›ë³¸ë„ í•¨ê»˜ ë³µì‚¬\n",
    "        for path in paths:\n",
    "            shutil.copy(path, os.path.join(cls_out_dir, os.path.basename(path)))\n",
    "\n",
    "    print(f\"âœ… í´ë˜ìŠ¤ë³„ crop ë¹„ìœ¨ {ratio:.0%} ì ìš© ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: {save_root}\")\n",
    "\n",
    "\n",
    "# ğŸ”§ ì‹¤í–‰ íŒŒë¼ë¯¸í„° ì§€ì •\n",
    "data_root = \"../data/train2\"  # ì›ë³¸ í•™ìŠµ ë°ì´í„° í´ë”\n",
    "save_root = \"../data/train2_augmented\"  # ì €ì¥í•  ìƒˆ í´ë”\n",
    "crop_ratio = 0.2  # ê° í´ë˜ìŠ¤ì—ì„œ crop ìƒì„±í•  ë¹„ìœ¨\n",
    "roof_height_ratio = 0.4  # ì´ë¯¸ì§€ ìƒë‹¨ ëª‡ % ìë¥¼ì§€\n",
    "\n",
    "# ğŸš€ í•¨ìˆ˜ ì‹¤í–‰\n",
    "generate_classwise_roof_crops(\n",
    "    data_root=data_root,\n",
    "    save_root=save_root,\n",
    "    ratio=crop_ratio,\n",
    "    height_ratio=roof_height_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
